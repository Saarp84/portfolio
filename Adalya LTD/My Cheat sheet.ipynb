{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import geoviews\n",
    "from geopy import distance\n",
    "\n",
    "\n",
    "import sympy as sp\n",
    "from linearmodels.panel import RandomEffects\n",
    "import statsmodels.api as sm\n",
    "from factor_analyzer import FactorAnalyzer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Phones format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_israeli_phone(phone_number):\n",
    "    \"\"\"\n",
    "    Clean and format Israeli phone numbers according to standard patterns.\n",
    "    \n",
    "    Args:\n",
    "        phone_number: A phone number string to format\n",
    "        \n",
    "    Returns:\n",
    "        Formatted phone number string or np.nan if invalid\n",
    "    \"\"\"\n",
    "    p = str(phone_number)\n",
    "    p = re.sub(r'[א-תa-zA-Z()!@#$%^&*_=+<>?/|\\\\\\[\\]{}.,]', '', p)\n",
    "    p = p.replace(\"-\", \"\").replace(\" \", \"\").replace(\"+972\", \"\").strip()\n",
    "    \n",
    "    if len(p) in [8, 9] and not p.startswith(\"0\"):\n",
    "        p = \"0\" + p\n",
    "    \n",
    "    if p.startswith((\"1700\", \"1800\")) and len(p) == 10:\n",
    "        return f\"{p[:4]}-{p[4:]}\"\n",
    "    elif p.startswith((\"072\", \"073\", \"074\", \"076\", \"077\", \"078\", \"079\")) and len(p) == 10:\n",
    "        return f\"{p[:3]}-{p[3:]}\"\n",
    "    elif len(p) == 10 and p.startswith(\"0\"):\n",
    "        return f\"{p[:3]}-{p[3:]}\"\n",
    "    elif len(p) == 9 and p.startswith(\"0\"):\n",
    "        return f\"{p[:2]}-{p[2:]}\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def clean_phone_numbers(df, column_name, new_column_name='טלפון'):\n",
    "    \"\"\"\n",
    "    Process phone numbers in a DataFrame column and add formatted numbers to a new column.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing phone numbers\n",
    "        column_name: Name of the column with raw phone numbers\n",
    "        new_column_name: Name for the new column with formatted numbers\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added formatted phone numbers column\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    result_df[new_column_name] = result_df[column_name].apply(format_israeli_phone)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ID \n",
    "- as a string - 9 digits with leading zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def id9(i):\n",
    "\n",
    "    if i is None:\n",
    "        return np.nan\n",
    "    if isinstance(i, float) and np.isnan(i):\n",
    "        return np.nan\n",
    "    \n",
    "    s = str(i).replace('\\u200e', '').strip()  \n",
    "    \n",
    "    if s.endswith('.0'):\n",
    "        s = s[:-2]\n",
    "    elif s.endswith('.'):\n",
    "        s = s[:-1]\n",
    "    \n",
    "    if not s:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        num = int(s)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n",
    "    if num == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    s = str(num)\n",
    "    \n",
    "    if len(s) < 9:\n",
    "        s = s.zfill(9)\n",
    "    elif len(s) > 9:\n",
    "        s = s[:9]\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sampling Data Randomly by Conditions & Row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(df):\n",
    "\n",
    "    data_for_mimun = df.copy()\n",
    "    data_for_mimun['row_number'] = range(1,len(data_for_mimun)+1)\n",
    "\n",
    "    values = [1, 2, 3, 4]\n",
    "\n",
    "    conditions0 = [\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'תעשייה') & (data_for_mimun['קבוצת גודל'] == 'עצמאים וללא מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'בינוי') & (data_for_mimun['קבוצת גודל'] == 'עצמאים וללא מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'מסחר') & (data_for_mimun['קבוצת גודל'] == 'עצמאים וללא מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 4 == 1) & (data_for_mimun['ענף'] == 'שירותים') & (data_for_mimun['קבוצת גודל'] == 'עצמאים וללא מועסקים'),\n",
    "    ]\n",
    "\n",
    "    data_for_mimun['size_plus_anaf'] = np.select(conditions0, values, default=None)\n",
    "\n",
    "    data_for_t0 = data_for_mimun[data_for_mimun['size_plus_anaf'].notnull()]\n",
    "\n",
    "    conditions1 = [\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'תעשייה') & (data_for_mimun['קבוצת גודל'] == '1-4 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'בינוי') & (data_for_mimun['קבוצת גודל'] == '1-4 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'מסחר') & (data_for_mimun['קבוצת גודל'] == '1-4 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'שירותים') & (data_for_mimun['קבוצת גודל'] == '1-4 מועסקים'),\n",
    "    ]\n",
    "\n",
    "    data_for_mimun['size_plus_anaf'] = np.select(conditions1, values, default=None)\n",
    "\n",
    "    data_for_t1 = data_for_mimun[data_for_mimun['size_plus_anaf'].notnull()]\n",
    "\n",
    "    conditions2 = [\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'תעשייה') & (data_for_mimun['קבוצת גודל'] == '5-19 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'בינוי') & (data_for_mimun['קבוצת גודל'] == '5-19 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 3 == 1) & (data_for_mimun['ענף'] == 'מסחר') & (data_for_mimun['קבוצת גודל'] == '5-19 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 5 == 1) & (data_for_mimun['ענף'] == 'שירותים') & (data_for_mimun['קבוצת גודל'] == '5-19 מועסקים'),\n",
    "    ]\n",
    "\n",
    "    data_for_mimun['size_plus_anaf'] = np.select(conditions2, values, default=None)\n",
    "\n",
    "    data_for_t2 = data_for_mimun[data_for_mimun['size_plus_anaf'].notnull()]\n",
    "\n",
    "\n",
    "    conditions3 = [\n",
    "        (data_for_mimun['row_number'] % 4 == 1) & (data_for_mimun['ענף'] == 'תעשייה') & (data_for_mimun['קבוצת גודל'] == '20-99 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 4 == 1) & (data_for_mimun['ענף'] == 'בינוי') & (data_for_mimun['קבוצת גודל'] == '20-99 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 4 == 1) & (data_for_mimun['ענף'] == 'מסחר') & (data_for_mimun['קבוצת גודל'] == '20-99 מועסקים'),\n",
    "        (data_for_mimun['row_number'] % 4 == 1) & (data_for_mimun['ענף'] == 'שירותים') & (data_for_mimun['קבוצת גודל'] == '20-99 מועסקים'),\n",
    "    ]\n",
    "\n",
    "    data_for_mimun['size_plus_anaf'] = np.select(conditions3, values, default=None)\n",
    "\n",
    "    data_for_t3 = data_for_mimun[data_for_mimun['size_plus_anaf'].notnull()]\n",
    "\n",
    "    mimun_data = pd.concat([data_for_t0,data_for_t1,data_for_t2,data_for_t3], ignore_index=True)\n",
    "    \n",
    "    return mimun_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Text to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df(path):\n",
    "    l = []\n",
    "    file = open(path, \"r\", encoding=\"utf-8\")\n",
    "    for i in file:\n",
    "        l.append(i[:132])\n",
    "\n",
    "#     l1 = []\n",
    "#     file1 = open(path, \"r\")\n",
    "#     for i in file1:\n",
    "#         l1.append(i)\n",
    "\n",
    "    idn = []\n",
    "    family = []\n",
    "    first = []\n",
    "    bod = []\n",
    "    year = []\n",
    "    identified = []\n",
    "    kind = []\n",
    "    jan = []\n",
    "    feb = []\n",
    "    march = []\n",
    "    apr = []\n",
    "    may = []\n",
    "    june = []\n",
    "    july = []\n",
    "    aug = []\n",
    "    sept = []\n",
    "    octob = []\n",
    "    novem = []\n",
    "    december = []\n",
    "    wage = []\n",
    "    employer = []\n",
    "    file_n = []\n",
    "    report = []\n",
    "    branch4 = []\n",
    "    for i in l:\n",
    "        idn.append(i[:9])\n",
    "        family.append(i[9:26][::-1])\n",
    "        first.append(i[26:41][::-1])\n",
    "        bod.append(i[41:49])\n",
    "        year.append(i[49:53])\n",
    "        identified.append(i[53:54])\n",
    "        kind.append(i[54:64][::-1])\n",
    "        december.append(i[64:65])\n",
    "        novem.append(i[65:66])\n",
    "        octob.append(i[66:67])\n",
    "        sept.append(i[67:68])\n",
    "        aug.append(i[68:69])\n",
    "        july.append(i[69:70])\n",
    "        june.append(i[70:71])\n",
    "        may.append(i[71:72])\n",
    "        apr.append(i[72:73])\n",
    "        march.append(i[73:74])\n",
    "        feb.append(i[74:75])\n",
    "        jan.append(i[75:76])\n",
    "        wage.append(i[76:86])\n",
    "        employer.append(i[86:118][::-1])\n",
    "        file_n.append(i[118:127])\n",
    "        report.append(i[127:128])\n",
    "        branch4.append(i[128:132])\n",
    "#     report[-1] = l1[-1][-1]\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['ID'] = idn\n",
    "    df['family_name'] = family\n",
    "    df['first_name'] = first\n",
    "    df['date_of_birth'] = bod\n",
    "    df['year_of_wage'] = year\n",
    "    df['identified'] = identified\n",
    "    df['status'] = kind\n",
    "    df['worked12'] = december\n",
    "    df['worked11'] = novem\n",
    "    df['worked10'] = octob\n",
    "    df['worked9'] = sept\n",
    "    df['worked8'] = aug\n",
    "    df['worked7'] = july\n",
    "    df['worked6'] = june\n",
    "    df['worked5'] = may\n",
    "    df['worked4'] = apr\n",
    "    df['worked3'] = march\n",
    "    df['worked2'] = feb\n",
    "    df['worked1'] = jan\n",
    "    df['wage'] = wage\n",
    "    df['employer_name'] = employer\n",
    "    df['file_num'] = file_n\n",
    "    df['report'] = report\n",
    "    df['branch4'] = branch4\n",
    "\n",
    "    df['identified'] = pd.Series(np.where(df.identified.values == 'כ', 1, 0),df.index)\n",
    "    df['worked12'] = pd.Series(np.where(df.worked12.values == 'כ', 1, 0),df.index)\n",
    "    df['worked11'] = pd.Series(np.where(df.worked11.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked10'] = pd.Series(np.where(df.worked10.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked9'] = pd.Series(np.where(df.worked9.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked8'] = pd.Series(np.where(df.worked8.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked7'] = pd.Series(np.where(df.worked7.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked6'] = pd.Series(np.where(df.worked6.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked5'] = pd.Series(np.where(df.worked5.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked4'] = pd.Series(np.where(df.worked4.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked3'] = pd.Series(np.where(df.worked3.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked2'] = pd.Series(np.where(df.worked2.values == 'כ', 1, 0),df.index)                           \n",
    "    df['worked1'] = pd.Series(np.where(df.worked1.values == 'כ', 1, 0),df.index)                           \n",
    "\n",
    "\n",
    "    df['status'] = pd.Series(np.where(df.status.values == 'עובד      ', 'employed', np.where(df.status.values == 'עצמאי     ','freelance',np.nan)),df.index)\n",
    "    df['report'] = pd.Series(np.where(df.report.values == 'ס', 'final',np.where(df.report.values == 'ש','yearly',\n",
    "                                                        np.where(df.report.values == 'ח','monthly',np.nan))),df.index)\n",
    "    # l = list(df['wage'])\n",
    "    df = df.sort_values(['identified'],ascending = [False]).drop_duplicates(subset = ['ID','year_of_wage','employer_name']\n",
    "                                                                           ).reset_index().drop(['index'], axis = 1)\n",
    "    \n",
    "\n",
    "    def int_no_minus(n):\n",
    "        try:\n",
    "            return int(n)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    df['wage'] = df['wage'].apply(int_no_minus)\n",
    "\n",
    "    df['DB'] = pd.to_datetime(df['date_of_birth'],errors = 'coerce')\n",
    "    df['count_worked'] = df.worked1+df.worked2+df.worked3+df.worked4+df.worked5+df.worked6+df.worked7+df.worked8+df.worked9+df.worked10+df.worked11+df.worked12\n",
    "    df.loc[(df['count_worked'] == 0) & (df['wage'] > 0),['worked'+str(i) for i in range(1,13)]] = 1\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colleges1 = pd.read_excel(r'college_data.xlsx', sheet_name='Students')\n",
    "israel = mpimg.imread('israel-vector-country-map-outline-2JFP21J.jpg')\n",
    "\n",
    "def map_from_image(colleges1,israel):\n",
    "    fig, ax = plt.subplots(figsize=(9, 8))\n",
    "    ax.imshow(israel, extent=[32.37, 37.72, 28.8, 33.75])\n",
    "\n",
    "    ax.scatter(colleges1['אורך'], colleges1['רוחב'], color='gray', alpha=0.7)\n",
    "\n",
    "    ax.set_xlim([32.8, 37])\n",
    "    ax.set_ylim([27.5, 33.6])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_path_high = \"ne_10m_admin_0_countries_isr.shp\"\n",
    "colors = [\"red\", \"yellow\", \"green\"]\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "norm = Normalize(vmin=-1, vmax=1)\n",
    "\n",
    "def changes_df(df, var):\n",
    "    df1 = df.groupby(by=['רשות', 'סקר'], as_index=False)[var].mean()\n",
    "    \n",
    "    years = [2021, 2022, 2023]\n",
    "    d = {}\n",
    "    for rashut in df['רשות'].unique():\n",
    "        drashut = df[df['רשות'] == rashut]\n",
    "        \n",
    "        rashut_means = []\n",
    "        diffs = []\n",
    "        for year in years:\n",
    "            mean_value = drashut[drashut['סקר'] == year][var].mean()\n",
    "            rashut_means.append(mean_value)\n",
    "        \n",
    "        for i in range(1, 3):\n",
    "            diff = round((rashut_means[i] - rashut_means[i-1]) / rashut_means[i-1], 2)\n",
    "            diffs.append(diff)\n",
    "        \n",
    "        d[rashut] = diffs\n",
    "    \n",
    "    dchanges = pd.DataFrame(d).transpose()\n",
    "    dchanges.columns = ['שיעור שינוי 21-22', 'שיעור שינוי 22-23']\n",
    "    dchanges['רשות'] = dchanges.index\n",
    "    \n",
    "    dchanges = dchanges.reset_index(drop=True)\n",
    "    dchanges = dchanges[['רשות', 'שיעור שינוי 21-22', 'שיעור שינוי 22-23']]\n",
    "\n",
    "    return dchanges\n",
    "\n",
    "def map_by_grade(df, var):\n",
    "    colors = [\"red\", \"yellow\", \"green\"]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "    norm = Normalize(vmin=-1, vmax=1)\n",
    "    \n",
    "    latlng = pd.read_excel(r\"C:\\Users\\SaarPardo\\Box\\צוות תעסוקה\\סוכנות לעסקים קטנים\\סקרים\\מדד ידידות רשויות מקומיות\\2024\\פאנל שביעות רצון - מחקר\\latlong rashuyot.xlsx\")\n",
    "    latlng = latlng[['רשות', 'אורך', 'רוחב']]\n",
    "\n",
    "    df1 = changes_df(df, var)\n",
    "    df1 = df1.merge(latlng, how='left', on='רשות')\n",
    "\n",
    "    columns = ['שיעור שינוי 21-22', 'שיעור שינוי 22-23']\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    for i, column in enumerate(columns):\n",
    "        gdf = gpd.GeoDataFrame(df1, geometry=gpd.points_from_xy(df1['רוחב'], df1['אורך']))\n",
    "        world = gpd.read_file(map_path_high)\n",
    "        \n",
    "        world.plot(ax=axes[i], color='linen', edgecolor='white')\n",
    "        \n",
    "        gdf.plot(ax=axes[i], markersize = abs(df1[column]) * 80,\n",
    "                 alpha=0.9, \n",
    "                 column=column, \n",
    "                 cmap=cmap, \n",
    "                 norm=norm)\n",
    "        \n",
    "        for _, row in gdf.iterrows():\n",
    "            if abs(row[column]) > 0.5:\n",
    "                # Adjust placement based on index to alternate positions and reduce overlap\n",
    "                if _ % 2 == 0:\n",
    "                    x_offset = 0.02\n",
    "                    y_offset = 0.01\n",
    "                    ha = 'left'\n",
    "                else:\n",
    "                    x_offset = -0.02\n",
    "                    y_offset = -0.01\n",
    "                    ha = 'right'\n",
    "                \n",
    "                axes[i].text(row['רוחב'] + x_offset, row['אורך'] + y_offset, row['רשות'][::-1],\n",
    "                             fontsize=(7 + (abs(row[column]))**2),  # Slightly reduce the font size scaling\n",
    "                             ha=ha, \n",
    "                             va='bottom',  \n",
    "                             color='black', \n",
    "                             bbox=dict(facecolor='none', edgecolor='none', boxstyle='round,pad=0.3'))\n",
    "                \n",
    "        axes[i].set_ylim([31, 33.5])  # Set y-axis limits\n",
    "        axes[i].set_xlim([34.2, 35.9])  # Set x-axis limits\n",
    "        axes[i].set_title(f'{column[12::]}:{column[11::-1]} - {var[::-1]}' , fontsize=10, pad=10)\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markersize(df, mins=5, maxs=100):\n",
    "    if df['meonot'].max() == df['meonot'].min():\n",
    "        df['marksize'] = mins\n",
    "    else:\n",
    "        min_size = mins  \n",
    "        max_size = maxs  \n",
    "        sizes = ((df['meonot'] - df['meonot'].min()) / \n",
    "                (df['meonot'].max() - df['meonot'].min()) * \n",
    "                (max_size - min_size) + min_size)\n",
    "        df['marksize'] = sizes\n",
    "    \n",
    "    return df\n",
    "\n",
    "def map_labels_func(df, var, minf=2, maxf=10):\n",
    "    df_unique = df.sort_values('marksize', ascending=False).drop_duplicates(subset='name', keep='first')\n",
    "    \n",
    "    min_lng = df_unique['longitude'].min() - 0.08\n",
    "    max_lng = df_unique['longitude'].max() + 0.08\n",
    "    min_lat = df_unique['latitude'].min() - 0.08\n",
    "    max_lat = df_unique['latitude'].max() + 0.08\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(df_unique, geometry=gpd.points_from_xy(df_unique.longitude, df_unique.latitude))\n",
    "    world = gpd.read_file(\"C:/Users/SaarPardo/Desktop/מיפוי חדש משפחתונים/isr mapping/ne_10m_admin_0_countries_isr.shp\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    world.plot(ax=ax, color=(250/255, 250/255, 250/255), edgecolor=(230/255, 230/255, 230/255))\n",
    "    \n",
    "    unique_values = df_unique[var].unique()\n",
    "    colors = {unique_values[0]: 'teal', unique_values[1]: 'orange'}\n",
    "    gdf.plot(ax=ax, column=var, color=gdf[var].map(colors), legend=True, \n",
    "             markersize=df_unique['marksize'], alpha=0.35)\n",
    "    \n",
    "    font_sizes = ((df_unique['marksize'] - df_unique['marksize'].min()) / \n",
    "                 (df_unique['marksize'].max() - df_unique['marksize'].min()) * \n",
    "                 (maxf - minf) + minf)\n",
    "    \n",
    "    texts = []\n",
    "    df_sorted = df_unique.sort_values('marksize', ascending=False)\n",
    "    direction_flags = [(-0.01, 0), (0.01, 0), (0, -0.01), (0, 0.01)]  # Up, Down, Left, Right\n",
    "    direction_idx = 0\n",
    "    \n",
    "    for idx, row in df_sorted.iterrows():\n",
    "        label = f\"{row['total']} :{row['name'][::-1]}\"\n",
    "        offset_x, offset_y = direction_flags[direction_idx]\n",
    "        direction_idx = (direction_idx + 1) % len(direction_flags)  # Alternate direction\n",
    "        \n",
    "        text = ax.text(row['longitude'] + offset_x * 0.5, \n",
    "                       row['latitude'] + offset_y * 0.5, \n",
    "                       label, fontsize=font_sizes[idx], alpha=0.8,\n",
    "                       ha='center', va='center')\n",
    "        texts.append(text)\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=15, label=unique_values[1][::-1]),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='teal', markersize=15, label=unique_values[0][::-1])\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', fontsize=15)\n",
    "    ax.set_xlim([min_lng, max_lng])\n",
    "    ax.set_ylim([min_lat, max_lat])\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "map = map_labels_func(markersize(meonot,mins=20,maxs=400),'type',\n",
    "                     minf=3 , maxf=10)\n",
    "map.savefig(\"map4.pdf\", format=\"pdf\", dpi=150, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df=pca_df.dropna()\n",
    "\n",
    "fa = FactorAnalyzer(n_factors=19, rotation=None)\n",
    "fa.fit(pca_df)\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev\n",
    "\n",
    "plt.scatter(range(1,pca_df.shape[1]+1),ev)\n",
    "plt.plot(range(1,pca_df.shape[1]+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(n_factors=3, rotation='varimax')\n",
    "fa.fit(pca_df)\n",
    "\n",
    "factor_loadings = fa.loadings_\n",
    "loadings_df = pd.DataFrame(factor_loadings, index=pca_df.columns, columns=['Factor 1', 'Factor 2', 'Factor 3'])\n",
    "loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Cornbach's Alpha (Manual calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha(data):\n",
    "    # Calculate number of items (N)\n",
    "    n_items = data.shape[1]\n",
    "    \n",
    "    # Calculate item variances (v̄)\n",
    "    item_variances = data.var(axis=0, ddof=1)\n",
    "    \n",
    "    # Calculate average inter-item covariance (c̄)\n",
    "    # First get covariance matrix\n",
    "    covariance_matrix = data.cov()\n",
    "    \n",
    "    # Calculate average covariance (excluding diagonal variances)\n",
    "    n = covariance_matrix.shape[0]\n",
    "    # Use numpy to get diagonal\n",
    "    covariance_sum = (covariance_matrix.sum().sum() - np.diag(covariance_matrix).sum())\n",
    "    avg_covariance = covariance_sum / (n * (n - 1))\n",
    "    \n",
    "    # Apply Cronbach's alpha formula: α = Nc̄ / (v̄ + (N-1)c̄)\n",
    "    avg_variance = item_variances.mean()\n",
    "    alpha = (n_items * avg_covariance) / (avg_variance + (n_items - 1) * avg_covariance)\n",
    "    \n",
    "    # Since your code expects two return values, let's return alpha and None\n",
    "    return alpha, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Entorpy Blancing - [Hainmueller (2012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeb import entbal\n",
    "\n",
    "mydata[\"T\"] = (mydata[\"sug_seker\"] == \"טלפוני\").astype(int)\n",
    "\n",
    "X = pd.get_dummies(mydata[[\"size\", \"sector\", \"A1\"]], drop_first=False)\n",
    "\n",
    "# התאמה לפי ATT (איזון הביקורת לפי הטיפול)\n",
    "eb = entbal()\n",
    "eb.fit(X, mydata[\"T\"], estimand=\"ATT\")\n",
    "\n",
    "mydata[\"weight\"] = eb.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata_needed = mydata[mydata[\"A1\"] == \"זקוק למימון\"].copy()\n",
    "\n",
    "mydata_needed[\"T\"] = (mydata_needed[\"sug_seker\"] == \"טלפוני\").astype(int)\n",
    "\n",
    "X1 = pd.get_dummies(mydata_needed[[\"size\", \"sector\"]], drop_first=False)\n",
    "\n",
    "# התאמה לפי ATT (איזון הביקורת לפי הטיפול)\n",
    "eb = entbal()\n",
    "eb.fit(X1, mydata_needed[\"T\"], estimand=\"ATT\")\n",
    "\n",
    "mydata_needed[\"en_weight\"] = eb.W \n",
    "\n",
    "mydata_needed[\"classic_w\"] = np.where(mydata_needed[\"en_weight\"] == 1, mydata_needed[\"en_weight\"], \n",
    "                                mydata_needed[\"en_weight\"]*len(mydata_needed[mydata_needed['sug_seker']=='אינטרנטי']))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
